{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec1a0786",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-19T10:40:00.162245Z",
     "iopub.status.busy": "2025-01-19T10:40:00.161966Z",
     "iopub.status.idle": "2025-01-19T10:40:05.745423Z",
     "shell.execute_reply": "2025-01-19T10:40:05.744417Z"
    },
    "papermill": {
     "duration": 5.589696,
     "end_time": "2025-01-19T10:40:05.747754",
     "exception": false,
     "start_time": "2025-01-19T10:40:00.158058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b8aa62f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T10:40:05.754513Z",
     "iopub.status.busy": "2025-01-19T10:40:05.754165Z",
     "iopub.status.idle": "2025-01-19T10:40:05.764501Z",
     "shell.execute_reply": "2025-01-19T10:40:05.763936Z"
    },
    "papermill": {
     "duration": 0.015142,
     "end_time": "2025-01-19T10:40:05.765993",
     "exception": false,
     "start_time": "2025-01-19T10:40:05.750851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set fixed seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63753c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T10:40:05.771813Z",
     "iopub.status.busy": "2025-01-19T10:40:05.771544Z",
     "iopub.status.idle": "2025-01-19T10:40:05.775625Z",
     "shell.execute_reply": "2025-01-19T10:40:05.774919Z"
    },
    "papermill": {
     "duration": 0.008729,
     "end_time": "2025-01-19T10:40:05.777153",
     "exception": false,
     "start_time": "2025-01-19T10:40:05.768424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define dataset paths and parameters\n",
    "dataset_dir = \"/kaggle/input/aug-v100\"  # Replace with your dataset path\n",
    "train_folder = os.path.join(dataset_dir, \"output\")\n",
    "val_folder = os.path.join(dataset_dir, \"val\")\n",
    "test_folder = os.path.join(dataset_dir, \"test\")\n",
    "folders = [\"Diabetic Retinopathy\", \"Glaucoma\", \"Healthy\", \"Macular Scar\", \"Myopia\"]\n",
    "image_size = 299  # Input image size for InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2591034b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T10:40:05.783047Z",
     "iopub.status.busy": "2025-01-19T10:40:05.782808Z",
     "iopub.status.idle": "2025-01-19T10:40:05.787564Z",
     "shell.execute_reply": "2025-01-19T10:40:05.786806Z"
    },
    "papermill": {
     "duration": 0.009489,
     "end_time": "2025-01-19T10:40:05.789218",
     "exception": false,
     "start_time": "2025-01-19T10:40:05.779729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate dataset mean and std\n",
    "def calculate_mean_std(dataset):\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    for images, _ in loader:\n",
    "        images = images.view(images.size(0), images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "    mean /= len(dataset)\n",
    "    std /= len(dataset)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f239e55f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T10:40:05.795053Z",
     "iopub.status.busy": "2025-01-19T10:40:05.794812Z",
     "iopub.status.idle": "2025-01-19T10:40:05.800446Z",
     "shell.execute_reply": "2025-01-19T10:40:05.799694Z"
    },
    "papermill": {
     "duration": 0.010243,
     "end_time": "2025-01-19T10:40:05.801968",
     "exception": false,
     "start_time": "2025-01-19T10:40:05.791725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        for class_label, class_name in enumerate(folders):\n",
    "            class_folder = os.path.join(folder_path, class_name)\n",
    "            if os.path.exists(class_folder):\n",
    "                for img_name in os.listdir(class_folder):\n",
    "                    img_path = os.path.join(class_folder, img_name)\n",
    "                    self.data.append((img_path, class_label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7961d3dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T10:40:05.808777Z",
     "iopub.status.busy": "2025-01-19T10:40:05.808521Z",
     "iopub.status.idle": "2025-01-19T10:41:12.198219Z",
     "shell.execute_reply": "2025-01-19T10:41:12.197341Z"
    },
    "papermill": {
     "duration": 66.398868,
     "end_time": "2025-01-19T10:41:12.203327",
     "exception": false,
     "start_time": "2025-01-19T10:40:05.804459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Mean: tensor([0.5828, 0.4277, 0.2689]), Std: tensor([0.3004, 0.2478, 0.1858])\n"
     ]
    }
   ],
   "source": [
    "# Create datasets for mean/std calculation\n",
    "combined_dataset = CustomDataset(train_folder, transform=transforms.ToTensor())\n",
    "mean, std = calculate_mean_std(combined_dataset)\n",
    "print(f\"Dataset Mean: {mean}, Std: {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa05e301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T10:41:12.211567Z",
     "iopub.status.busy": "2025-01-19T10:41:12.211285Z",
     "iopub.status.idle": "2025-01-19T10:41:12.215685Z",
     "shell.execute_reply": "2025-01-19T10:41:12.214873Z"
    },
    "papermill": {
     "duration": 0.010617,
     "end_time": "2025-01-19T10:41:12.217560",
     "exception": false,
     "start_time": "2025-01-19T10:41:12.206943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update transforms with calculated mean and std\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size), interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean.tolist(), std=std.tolist())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1718e6c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T10:41:12.225911Z",
     "iopub.status.busy": "2025-01-19T10:41:12.225601Z",
     "iopub.status.idle": "2025-01-19T10:41:12.384892Z",
     "shell.execute_reply": "2025-01-19T10:41:12.384089Z"
    },
    "papermill": {
     "duration": 0.165184,
     "end_time": "2025-01-19T10:41:12.386472",
     "exception": false,
     "start_time": "2025-01-19T10:41:12.221288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create datasets for train, validation, and test\n",
    "train_dataset = CustomDataset(train_folder, transform=transform)\n",
    "val_dataset = CustomDataset(val_folder, transform=transform)\n",
    "test_dataset = CustomDataset(test_folder, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e0717ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T10:41:12.392844Z",
     "iopub.status.busy": "2025-01-19T10:41:12.392565Z",
     "iopub.status.idle": "2025-01-19T10:41:12.396578Z",
     "shell.execute_reply": "2025-01-19T10:41:12.395798Z"
    },
    "papermill": {
     "duration": 0.009061,
     "end_time": "2025-01-19T10:41:12.398252",
     "exception": false,
     "start_time": "2025-01-19T10:41:12.389191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b65934a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T10:41:12.404567Z",
     "iopub.status.busy": "2025-01-19T10:41:12.404326Z",
     "iopub.status.idle": "2025-01-19T10:41:13.445739Z",
     "shell.execute_reply": "2025-01-19T10:41:13.444823Z"
    },
    "papermill": {
     "duration": 1.046973,
     "end_time": "2025-01-19T10:41:13.447989",
     "exception": false,
     "start_time": "2025-01-19T10:41:12.401016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100%|██████████| 104M/104M [00:00<00:00, 228MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception3(\n",
      "  (Conv2d_1a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2b_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv2d_3b_1x1): BasicConv2d(\n",
      "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_4a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Mixed_5b): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5c): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5d): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6a): InceptionB(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6b): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6c): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6d): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6e): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AuxLogits): InceptionAux(\n",
      "    (conv0): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      "  (Mixed_7a): InceptionD(\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7b): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7c): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=2048, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# **************************************************************\n",
    "\n",
    "# Load the pretrained InceptionV3 model\n",
    "model = models.inception_v3(pretrained=True)\n",
    "\n",
    "# Get the number of input features for the classifier\n",
    "num_features = model.fc.in_features  # Access the input features of the fully connected layer\n",
    "\n",
    "# Replace the fully connected layer with a custom Sequential block\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),  # Dropout with 50% probability\n",
    "    nn.Linear(num_features, len(folders))  # Output layer\n",
    ")\n",
    "\n",
    "# Verify the modified model architecture\n",
    "print(model)\n",
    "\n",
    "# **************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d233410a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T10:41:13.459620Z",
     "iopub.status.busy": "2025-01-19T10:41:13.459332Z",
     "iopub.status.idle": "2025-01-19T10:41:13.780042Z",
     "shell.execute_reply": "2025-01-19T10:41:13.779337Z"
    },
    "papermill": {
     "duration": 0.328744,
     "end_time": "2025-01-19T10:41:13.782115",
     "exception": false,
     "start_time": "2025-01-19T10:41:13.453371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # L2 regularization with weight_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71875f62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T10:41:13.790862Z",
     "iopub.status.busy": "2025-01-19T10:41:13.790545Z",
     "iopub.status.idle": "2025-01-19T12:05:57.644037Z",
     "shell.execute_reply": "2025-01-19T12:05:57.643003Z"
    },
    "papermill": {
     "duration": 5083.865428,
     "end_time": "2025-01-19T12:05:57.651462",
     "exception": false,
     "start_time": "2025-01-19T10:41:13.786034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Accuracy: 67.32%, Validation Accuracy: 67.56%\n",
      "Epoch 2/50, Train Accuracy: 75.38%, Validation Accuracy: 69.01%\n",
      "Epoch 3/50, Train Accuracy: 79.58%, Validation Accuracy: 67.36%\n",
      "Epoch 4/50, Train Accuracy: 81.02%, Validation Accuracy: 71.07%\n",
      "Epoch 5/50, Train Accuracy: 81.19%, Validation Accuracy: 70.87%\n",
      "Epoch 6/50, Train Accuracy: 82.50%, Validation Accuracy: 70.66%\n",
      "Epoch 7/50, Train Accuracy: 84.88%, Validation Accuracy: 68.39%\n",
      "Epoch 8/50, Train Accuracy: 86.65%, Validation Accuracy: 72.73%\n",
      "Epoch 9/50, Train Accuracy: 87.98%, Validation Accuracy: 73.35%\n",
      "Epoch 10/50, Train Accuracy: 88.01%, Validation Accuracy: 71.69%\n",
      "Epoch 11/50, Train Accuracy: 88.93%, Validation Accuracy: 70.04%\n",
      "Epoch 12/50, Train Accuracy: 89.73%, Validation Accuracy: 69.42%\n",
      "Epoch 13/50, Train Accuracy: 88.15%, Validation Accuracy: 68.39%\n",
      "Epoch 14/50, Train Accuracy: 90.08%, Validation Accuracy: 70.04%\n",
      "Epoch 15/50, Train Accuracy: 91.02%, Validation Accuracy: 73.35%\n",
      "Epoch 16/50, Train Accuracy: 87.84%, Validation Accuracy: 66.12%\n",
      "Epoch 17/50, Train Accuracy: 89.61%, Validation Accuracy: 73.76%\n",
      "Epoch 18/50, Train Accuracy: 90.74%, Validation Accuracy: 72.11%\n",
      "Epoch 19/50, Train Accuracy: 91.60%, Validation Accuracy: 71.90%\n",
      "Epoch 20/50, Train Accuracy: 91.52%, Validation Accuracy: 70.87%\n",
      "Epoch 21/50, Train Accuracy: 91.27%, Validation Accuracy: 71.07%\n",
      "Epoch 22/50, Train Accuracy: 89.67%, Validation Accuracy: 59.50%\n",
      "Epoch 23/50, Train Accuracy: 89.98%, Validation Accuracy: 71.49%\n",
      "Epoch 24/50, Train Accuracy: 90.94%, Validation Accuracy: 74.59%\n",
      "Epoch 25/50, Train Accuracy: 91.58%, Validation Accuracy: 67.77%\n",
      "Epoch 26/50, Train Accuracy: 91.27%, Validation Accuracy: 68.18%\n",
      "Epoch 27/50, Train Accuracy: 91.97%, Validation Accuracy: 71.49%\n",
      "Epoch 28/50, Train Accuracy: 92.17%, Validation Accuracy: 71.07%\n",
      "Epoch 29/50, Train Accuracy: 92.11%, Validation Accuracy: 72.31%\n",
      "Epoch 30/50, Train Accuracy: 90.72%, Validation Accuracy: 69.01%\n",
      "Epoch 31/50, Train Accuracy: 92.09%, Validation Accuracy: 67.36%\n",
      "Epoch 32/50, Train Accuracy: 91.33%, Validation Accuracy: 65.50%\n",
      "Epoch 33/50, Train Accuracy: 92.22%, Validation Accuracy: 69.83%\n",
      "Epoch 34/50, Train Accuracy: 92.07%, Validation Accuracy: 70.04%\n",
      "Epoch 35/50, Train Accuracy: 92.42%, Validation Accuracy: 63.43%\n",
      "Epoch 36/50, Train Accuracy: 92.01%, Validation Accuracy: 58.88%\n",
      "Epoch 37/50, Train Accuracy: 89.79%, Validation Accuracy: 69.42%\n",
      "Epoch 38/50, Train Accuracy: 90.49%, Validation Accuracy: 69.63%\n",
      "Epoch 39/50, Train Accuracy: 91.68%, Validation Accuracy: 70.66%\n",
      "Epoch 40/50, Train Accuracy: 91.72%, Validation Accuracy: 72.52%\n",
      "Epoch 41/50, Train Accuracy: 92.42%, Validation Accuracy: 70.87%\n",
      "Epoch 42/50, Train Accuracy: 92.91%, Validation Accuracy: 72.31%\n",
      "Epoch 43/50, Train Accuracy: 93.10%, Validation Accuracy: 70.25%\n",
      "Epoch 44/50, Train Accuracy: 91.95%, Validation Accuracy: 72.31%\n",
      "Epoch 45/50, Train Accuracy: 90.96%, Validation Accuracy: 67.98%\n",
      "Epoch 46/50, Train Accuracy: 91.50%, Validation Accuracy: 67.77%\n",
      "Epoch 47/50, Train Accuracy: 91.54%, Validation Accuracy: 70.25%\n",
      "Epoch 48/50, Train Accuracy: 92.15%, Validation Accuracy: 70.04%\n",
      "Epoch 49/50, Train Accuracy: 92.20%, Validation Accuracy: 70.04%\n",
      "Epoch 50/50, Train Accuracy: 92.28%, Validation Accuracy: 72.52%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(images)  # Get only the main outputs (logits)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Get the model output\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # If auxiliary logits are returned (i.e., aux_logits=True), unpack both outputs\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]  # Use only the primary logits\n",
    "                \n",
    "            _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "\n",
    "    # Print epoch results\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Save the best model\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), \"best_inceptionv3_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07fa4a17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T12:05:57.664216Z",
     "iopub.status.busy": "2025-01-19T12:05:57.663900Z",
     "iopub.status.idle": "2025-01-19T12:05:57.822531Z",
     "shell.execute_reply": "2025-01-19T12:05:57.821706Z"
    },
    "papermill": {
     "duration": 0.167085,
     "end_time": "2025-01-19T12:05:57.824261",
     "exception": false,
     "start_time": "2025-01-19T12:05:57.657176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1916460899.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_inceptionv3_model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model for testing\n",
    "model.load_state_dict(torch.load(\"best_inceptionv3_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11e519ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T12:05:57.837273Z",
     "iopub.status.busy": "2025-01-19T12:05:57.837003Z",
     "iopub.status.idle": "2025-01-19T12:06:06.245044Z",
     "shell.execute_reply": "2025-01-19T12:06:06.244260Z"
    },
    "papermill": {
     "duration": 8.416715,
     "end_time": "2025-01-19T12:06:06.247060",
     "exception": false,
     "start_time": "2025-01-19T12:05:57.830345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing phase\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Get the model output\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # If auxiliary logits are returned, unpack both outputs\n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]  # Use only the primary logits\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973a947e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T12:06:06.260897Z",
     "iopub.status.busy": "2025-01-19T12:06:06.260217Z",
     "iopub.status.idle": "2025-01-19T12:06:06.283873Z",
     "shell.execute_reply": "2025-01-19T12:06:06.283056Z"
    },
    "papermill": {
     "duration": 0.032085,
     "end_time": "2025-01-19T12:06:06.285442",
     "exception": false,
     "start_time": "2025-01-19T12:06:06.253357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.99%\n",
      "Test Precision: 0.7165\n",
      "Test Recall: 0.7199\n",
      "Test F1 Score: 0.7176\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6250315,
     "sourceId": 10128159,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6251460,
     "sourceId": 10129725,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6503486,
     "sourceId": 10505875,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5169.908525,
   "end_time": "2025-01-19T12:06:07.612719",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-19T10:39:57.704194",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
